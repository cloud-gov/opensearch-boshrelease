---
name: ingestor_cloudwatch

description: |
  This job runs Logstash process which ingests data by from cloudwatch

packages:
- logstash
- base-logstash-filters
- openjdk-21

templates:
  bin/ingestor_cloudwatch: bin/ingestor_cloudwatch.sh
  bin/pre-start: bin/pre-start
  config/bpm.yml.erb: config/bpm.yml
  config/input_and_output.conf.erb: config/input_and_output.conf
  config/logstash.yml.erb: config/logstash.yml
  config/jvm.options.erb: config/jvm.options
  config/ingestor-crt.erb: config/ssl/ingestor.crt
  config/ingestor-pem.erb: config/ssl/ingestor.pem
  config/ca.erb: config/ssl/opensearch.ca


consumes:
- name: opensearch
  type: opensearch
  optional: true

properties:
  logstash.heap_size:
    description: sets jvm heap sized
  logstash.heap_percentage:
    description: The percentage value used in the calculation to set the heap size.
    default: 46
  logstash.jvm_options:
    description: additional jvm options
    default: []
  logstash.log_level:
    description: The default logging level (e.g. WARN, DEBUG, INFO)
    default: info
  logstash.plugins:
    description: "Array of hashes describing logstash plugins to install"
    example:
    - {name: logstash-output-cloudwatchlogs, version: 2.0.0}
    default: []

  logstash.ecs_compatibility:
    description: Whether to enable ECS compatibility for geoip filters. See https://www.elastic.co/guide/en/logstash/current/plugins-filters-geoip.html#plugins-filters-geoip-ecs_compatibility
    default: "disabled"

  logstash.env:
    description: "a list of arbitrary key-value pairs to be passed on as process environment variables. eg: FOO: 123"
    default: []

  logstash.queue.type:
    description: Internal queuing model, "memory" for legacy in-memory based queuing and "persisted" for disk-based acked queueing.
    default: persisted
  logstash.queue.page_capacity:
    description: The page data files size. The queue data consists of append-only data files separated into pages.
    default: 250mb
  logstash.queue.max_events:
    description: The maximum number of unread events in the queue.
    default: 0
  logstash.queue.max_bytes:
    description: The total capacity of the queue in number of bytes.
    default: 1024mb
  logstash.queue.checkpoint.acks:
    description: The maximum number of acked events before forcing a checkpoint.
    default: 1024
  logstash.queue.checkpoint.writes:
    description: The maximum number of written events before forcing a checkpoint.
    default: 1024
  logstash.queue.checkpoint.interval:
    description: The interval in milliseconds when a checkpoint is forced on the head page.
    default: 1000

  logstash_ingestor.cloudwatch.prefix:
    description: "What prefix in cloudwatch you want to pull in"
    default: ["/aws/rds/instance/"]
  logstash_ingestor.cloudwatch.region:
    description: "Region for aws"
  logstash_ingestor.relp.port:
    description: Port to listen for RELP messages
    default: 2514

  logstash_parser.debug:
    description: Debug level logging
    default: false
  logstash_parser.message_max_size:
    description: "Maximum log message length.  Anything larger is truncated (TODO: move this to ingestor?)"
    default: 1048576
  logstash_parser.filters:
    description: "The configuration to embed into the logstash filters section. Can either be a set of parsing rules as a string or a list of hashes in the form of [{name: path_to_parsing_rules.conf}]"
    default: ''
  logstash_parser.outputs:
    description: |
      A list of output plugins, with a hash of options for each of them. Please refer to example below.
    example:
      inputs:
        - plugin: mongodb
          options:
            uri: 192.168.1.1
            database: logsearch
            collection: logs
    default: [ { plugin: "opensearch", options: {} } ]
  logstash_parser.workers:
    description: "The number of worker threads that logstash should use (default: auto = one per CPU)"
    default: auto
  logstash_parser.opensearch.idle_flush_time:
    description: "How frequently to flush events if the output queue is not full."
  logstash_parser.opensearch.document_id:
    description: "Use a specific, dynamic ID rather than an auto-generated identifier."
    default: ~
  logstash_parser.opensearch.index:
    description: "The specific, dynamic index name to write events to."
    default: "logstash-%{+YYYY.MM.dd}"
  logstash_parser.opensearch.index_type:
    description: "The specific, dynamic index type name to write events to."
    default: "%{@type}"
  logstash_parser.opensearch.routing:
    description: "The routing to be used when indexing a document."
  logstash_parser.opensearch.ssl.certificate:
    description: Node certificate for communication between logstash_parser and Opensearch
  logstash_parser.opensearch.ssl.private_key:
    description: Private key for communication between logstash_parser and Opensearch
  logstash_parser.opensearch.data_hosts:
    description: The list of opensearch data node IPs
  logstash_parser.opensearch.verification_mode:
    description: the verification mode, can be full or none
    default: "full"
  logstash_parser.timecop.reject_greater_than_hours:
    description: "Logs with timestamps greater than this many hours in the future won't be parsed and will get tagged with fail/timecop"
    default: 1
  logstash_parser.timecop.reject_less_than_hours:
    description: "Logs with timestamps less than this many hours in the past won't be parsed and will get tagged with fail/timecop"
    default: 24
  logstash_parser.enable_json_filter:
    description: "Toggles the if_it_looks_like_json.conf filter rule"
    default: false
  logstash_parser.wait_for_templates:
    description: "A list of index templates that need to be present in opensearch before the process starts"
    default: ["index_template"]